<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>R08UST's Blog - AIForSecurity</title><link href="/" rel="alternate"></link><link href="/feeds/aiforsecurity.atom.xml" rel="self"></link><id>/</id><updated>2021-03-09T00:00:00+08:00</updated><subtitle>Security &amp; AI Developer</subtitle><entry><title>论文笔记 ZeroWall: Detecting Zero-Day Web Attacks through Encoder-Decoder Recurrent Neural Networks</title><link href="/lun-wen-bi-ji-zerowall-detecting-zero-day-web-attacks-through-encoder-decoder-recurrent-neural-networks.html" rel="alternate"></link><published>2021-03-09T00:00:00+08:00</published><updated>2021-03-09T00:00:00+08:00</updated><author><name>R08UST</name></author><id>tag:None,2021-03-09:/lun-wen-bi-ji-zerowall-detecting-zero-day-web-attacks-through-encoder-decoder-recurrent-neural-networks.html</id><summary type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Waf(web application firewall)一般通过规则过滤/触发的异常的Web请求. 通过安全研究员对已知攻击特征的提取来构成并拓展特征库. 但基于特征的Waf难以对0Day漏洞进行检测. 故本文提出了一种Encoder-Decoder RNN架构的无监督学习方案对0Day漏洞进行检测.
本文的核心思想在与将0Day的检测问题转换为翻译质量评定的问题. 简单的来讲即通过训练一个翻译器来将正常web请求A再次翻译为A'. 而当异常的web请求B翻译为B'时, 由于神经网络对B的特征拟合较差故B'的翻译质量也会较差. 以此来判定B是一个异常的web请求&lt;/p&gt;
&lt;h2&gt;Method&lt;/h2&gt;
&lt;p&gt;对于Waf吞吐量的是十分重要的, 完全基于AI检测的waf器吞吐量是一个重大缺陷, 故本文采用waf旁路架构, 基于已有的waf框架过滤异常请求. 神经网络本身不进行过滤处理, 仅用于检测0Day漏洞, 并结合安全人员将已发现的漏洞编写成规则添加进规则库. 下图为系统的架构图
&lt;img alt="system" src="https://d3i71xaburhd42.cloudfront.net/c01326f394883b0ad0df27870e7b84a427f2fb73/3-Figure2-1.png"/&gt;
可以看出整个系统架构分为两个部分(实际是三个部分, 即传统的waf框架自身的运行在图中被省略, 当流量未触发waf规则时, 其会被放行).
在offline periodic retrain部分中, 其分为四个阶段数据积累, 词汇表构建(vocabulary), 词汇解析(token parser)以及训练. 其主要功能就是词汇表构建和训练. 以保证能对新出现的请求进行正常识别.
在online detection部分中, 其分为六个阶段请求过滤(在图中未体现), 词汇解析, 翻译, 异常检测以及人工调查.  一条请求经过上述六个阶段后 …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Waf(web application firewall)一般通过规则过滤/触发的异常的Web请求. 通过安全研究员对已知攻击特征的提取来构成并拓展特征库. 但基于特征的Waf难以对0Day漏洞进行检测. 故本文提出了一种Encoder-Decoder RNN架构的无监督学习方案对0Day漏洞进行检测.
本文的核心思想在与将0Day的检测问题转换为翻译质量评定的问题. 简单的来讲即通过训练一个翻译器来将正常web请求A再次翻译为A'. 而当异常的web请求B翻译为B'时, 由于神经网络对B的特征拟合较差故B'的翻译质量也会较差. 以此来判定B是一个异常的web请求&lt;/p&gt;
&lt;h2&gt;Method&lt;/h2&gt;
&lt;p&gt;对于Waf吞吐量的是十分重要的, 完全基于AI检测的waf器吞吐量是一个重大缺陷, 故本文采用waf旁路架构, 基于已有的waf框架过滤异常请求. 神经网络本身不进行过滤处理, 仅用于检测0Day漏洞, 并结合安全人员将已发现的漏洞编写成规则添加进规则库. 下图为系统的架构图
&lt;img alt="system" src="https://d3i71xaburhd42.cloudfront.net/c01326f394883b0ad0df27870e7b84a427f2fb73/3-Figure2-1.png"/&gt;
可以看出整个系统架构分为两个部分(实际是三个部分, 即传统的waf框架自身的运行在图中被省略, 当流量未触发waf规则时, 其会被放行).
在offline periodic retrain部分中, 其分为四个阶段数据积累, 词汇表构建(vocabulary), 词汇解析(token parser)以及训练. 其主要功能就是词汇表构建和训练. 以保证能对新出现的请求进行正常识别.
在online detection部分中, 其分为六个阶段请求过滤(在图中未体现), 词汇解析, 翻译, 异常检测以及人工调查.  一条请求经过上述六个阶段后, 被安全人员确认为异常请求后将其改写为waf规则并添加至规则库中.
下面对一些细节进行描述&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;词汇解析: 词汇解析主要分3个模块, 词汇表构建(分词), 词汇序列化以及词嵌入 &lt;ol&gt;
&lt;li&gt;词汇表构建(分词): 将每一条请求根据空格以及标点进行切分, 随后将无用的词汇(变量)和一些无意义的词汇(&amp;amp;, = 这些在语句中大量出现的词)替换为占位符(placeholder). 最后将出现频率过高以及过低的词汇删除来构成词汇表&lt;/li&gt;
&lt;li&gt;序列化: 仅保留出现在词汇表中的词, 以及替换变量为占位符&lt;/li&gt;
&lt;li&gt;词嵌入: 使用word2vec进行词表示&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;翻译器: 翻译器基于Encoder - Decoder架构. &lt;ol&gt;
&lt;li&gt;Encoder: 基于LSTM模型, 将输入的请求经过分词, 序列化以及词嵌入后作为输入输入值LSTM模型&lt;/li&gt;
&lt;li&gt;Decoder: 基于LSTM模型, Encoder接受到终止词后, 将其生成的预测和权重交付给Decoder, Decoder根据输入每一步生成预测结果.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;异常检测: 前面提到本文将异常检测的问题转化为翻译质量测评问题, 在翻译质量评测中通常使用BLEU指标. 本文简单的将1 - BLEU 作为异常的可能性&lt;/li&gt;
&lt;li&gt;白名单: 即使神经网络不再作为直接的过滤器, 但巨大的网络吞吐量对神经网络仍然无法处理, 故本文将已经处理过的请求Hash处理后保存下来, 以此进行过滤.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;实验&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;数据: 持续收集了8天的企业的网络流量&lt;ol&gt;
&lt;li&gt;训练集与测试集: 将8天的流量两两分为7分, 头一天的作为训练集, 余下的作为测试集&lt;/li&gt;
&lt;li&gt;Ground Truth与测试指标: Ground Truth由安全工程师进行验证, 测试指标为Precision, Recall以及F1. 见图二&lt;/li&gt;
&lt;li&gt;可能性址标: 实验中使用CDF(Cumulative Distribution Function, 累积分布函数)对GLUE, BLUE, NIST, CHRF进行测试, 实验显示BLUE的效果最佳. 见图三&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;设备&lt;ol&gt;
&lt;li&gt;CPU: Intel(R) Xeon(R) Gold 6148 CPU2.40GHz ∗ 2&lt;/li&gt;
&lt;li&gt;RAM: 512GB RAM&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;结论&lt;/h2&gt;
&lt;p&gt;本文贡献在于将异常检测问题转换为机器翻译质量评测问题, 以及白名单机制减少无效推理过程(感觉这一步依然可以进行优化). 
但也存在一些问题1. 无法防御数据投毒, 虽然文中作者解释waf会对这个进行处理, 但实际上waf不会对新类型数据进行过滤. 2. 相对来说数据量较少. 3. 文中没有提到对潜在的0day进行过滤, 虽然文中提出在大量正常样本的情况下, 少量的异常样本影响不大. 但正如前段时间爆出的qq邮箱会将某特定字段翻译为一段地址一样. 很难确定这一点没有影响. 很可能会导致一些漏报.  &lt;/p&gt;</content><category term="AIForSecurity"></category></entry></feed>